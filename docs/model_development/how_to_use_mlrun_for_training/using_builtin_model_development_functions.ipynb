{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using MLRun's Builtin Development Functions\n",
    "\n",
    "If you have the data, we got you covered in code. MLRun's [Functions Marketplace](https://www.mlrun.org/marketplace)\n",
    "has many training functions that utilize MLRun's quality of life features. We will use one of the main training\n",
    "functions in MLRun's Functions Marketplace named `auto-trainer` as an example.\n",
    "\n",
    "[**Auto Trainer**](https://www.mlrun.org/marketplace/functions/master/auto_trainer/latest/documentation/) is a highly\n",
    "customizable MLRun training function with multiple parameters to experiment and achieve the best and most agile\n",
    "solution to your needs.\n",
    "\n",
    "Remember, there are more functions in the marketplace, you may check the **Model Training** category and see for\n",
    "yourself:\n",
    "\n",
    "<img src=\"./model_training_category_checked.png\" alt=\"Model Training category checked\"/>\n",
    "\n",
    "If you wish to use your own training function, you can click here to see\n",
    "[how to apply MLRun to an existing code]().\n",
    "\n",
    "We will cover here the 3 most common handlers of any training function: `train`, `evaluate` and `predict`, using the\n",
    "Auto Trainer as our example."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "The main and default handler of any training function is called `\"train\"`. In the Auto Trainer this handler will perform\n",
    "an ML training function using SciKit-Learn's API, meaning the function follows the structure bellow:\n",
    "\n",
    "1. **Get the data**: Get the dataset passed to a local path.\n",
    "2. **Split the data into datasets**: Split the given data into a training set and a testing set.\n",
    "3. **Get the model**: Initialize a model instance out of a given class or load a provided model. The supported classes\n",
    "  are anything based on `sklearn.Estimator`, `xgboost.XGBModel`, `lightgbm.LGBMModel`, including custom code as well.\n",
    "4. **Train**: Call the model's `fit` method to train it on the training set.\n",
    "5. **Test**: Test the model on the testing set.\n",
    "6. **Log**: Calculate the metrics and produce the artifacts to log the results and plots.\n",
    "\n",
    "MLRun is orchestrating on all the steps above. The training is done with our shortcut function `apply_mlrun` that\n",
    "enable the automatic logging and further features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameters\n",
    "\n",
    "* `context` - MLRun context.\n",
    "\n",
    "**Model Parameters**\n",
    "\n",
    "*Parameters to initialize a new model object or load a logged one for retraining.*\n",
    "\n",
    "* `model_class`: `str` - The class of the model to initialize. Can be a module path like\n",
    "  `\"sklearn.linear_model.LogisticRegression\"` or a custom model passed through the custom objects parameters below.\n",
    "  Only one of `model_class` and `model_path` can be given.\n",
    "* `model_path`: `str` - A `ModelArtifact` URI to load and retrain. Only one of `model_class` and `model_path` can be\n",
    "  given.\n",
    "* `model_kwargs`: `dict` - Additional parameters to pass onto the initialization of the model object (the model's class\n",
    "  `__init__` method).\n",
    "\n",
    "**Data parameters**\n",
    "\n",
    "*Parameters to get a dataset and prepare it for training, splitting into training and testing if required.*\n",
    "\n",
    "* `dataset`: `Union[str, list, dict]` - The dataset to train the model on.\n",
    "  * Can be passed as part of `inputs` to be parsed as `mlrun.DataItem`, meaning it supports either a URI or a\n",
    "    FeatureVector.\n",
    "  * Can be passed as part of `params`, meaning it can be a `list` or a `dict`.\n",
    "* `drop_columns`: `Union[str, int, List[str], List[int]]` - columns to drop from the dataset. Can be passed as strings\n",
    "  representing the column names or integers representing the column numbers.\n",
    "* `test_set`: `Union[str, list, dict]` - The test set to test the model with post training. Notice only one of\n",
    "  `test_set` or `train_test_split_size` is expected.\n",
    "  * Can be passed as part of `inputs` to be parsed as `mlrun.DataItem`, meaning it supports either a URI or a\n",
    "    FeatureVector.\n",
    "  * Can be passed as part of `params`, meaning it can be a `list` or a `dict`.\n",
    "* `train_test_split_size`: `float` = `0.2` - The proportion of the dataset to include in the test split. The size of the\n",
    "  Training set is set to the complement of this value. Must be between 0.0 and 1.0. Defaulted to 0.2\n",
    "* `label_columns`: `Union[str, int, List[str], List[int]]` - The target label(s) of the column(s) in the dataset. Can\n",
    "  be passed as strings representing the column names or integers representing the column numbers.\n",
    "* `random_state`: `int` - Random state (seed) for `train_test_split`.\n",
    "\n",
    "**Train parameters**\n",
    "\n",
    "*Parameters to pass to the `fit` method of the model object.*\n",
    "\n",
    "* `train_kwargs`: `dict` - Additional parameters to pass onto the `fit` method.\n",
    "\n",
    "**Logging parameters**\n",
    "\n",
    "*Parameters to control the automatic logging feature of MLRun. You may adjust the logging outputs to your desire and if\n",
    "not passed, a default list of artifacts and metrics will be produced and calculated.*\n",
    "\n",
    "* `model_name`: `str` = `\"model`\" - The model’s name to use for storing the model artifact, default to ‘model’.\n",
    "* `tag`: `str` - The model’s tag to log with.\n",
    "* `sample_set`: `Union[str, list, dict]` - A sample set of inputs for the model for logging its stats along the model in\n",
    "  favour of model monitoring. If not given, the training set will be used instead.\n",
    "  * Can be passed as part of `inputs` to be parsed as `mlrun.DataItem`, meaning it supports either a URI or a\n",
    "    FeatureVector.\n",
    "  * Can be passed as part of `params`, meaning it can be a `list` or a `dict`.\n",
    "* `_artifacts`: `Dict[str, Union[list, dict]]` - Additional artifacts to produce post training. See the\n",
    "  `ArtifactsLibrary` of the desired framework to see the available list of artifacts.\n",
    "* `_metrics`: `Union[List[str], Dict[str, Union[list, dict]]]` - Additional metrics to calculate post training. See how\n",
    "  to pass metrics and custom metrics in the `MetricsLibrary` of the desired framework.\n",
    "* `apply_mlrun_kwargs`: `dict` - Framework specific `apply_mlrun` key word arguments. Refer to the framework of choice\n",
    "  to know more ([SciKit-Learn](), [XGBoost]() or [LightGBM]())\n",
    "\n",
    "**Custom objects parameters**\n",
    "\n",
    "*Parameters to include custom objects like custom model class, metric code and artifact plan. Keep in mind that the\n",
    "model artifact created will be logged with the custom objects, so if `model_path` is used, the custom objects used to\n",
    "train it are not required for loading it, it will happen automatically.*\n",
    "\n",
    "* `custom_objects_map`: `Union[str, Dict[str, Union[str, List[str]]]]` - A map of all the custom objects required for\n",
    "  loading, training and testing the model. Can be passed as a dictionary or a json file path. Each key is a path to a\n",
    "  python file and its value is the custom object name to import from it. If multiple objects needed to be imported from\n",
    "  the same py file a list can be given. For example:\n",
    "  ```python\n",
    "  {\n",
    "      \"/.../custom_model.py\": \"MyModel\",\n",
    "      \"/.../custom_objects.py\": [\"object1\", \"object2\"]\n",
    "  }\n",
    "  ```\n",
    "  All the paths will be accessed from the given 'custom_objects_directory', meaning each py file will be read from\n",
    "  'custom_objects_directory/<MAP VALUE>'. If the model path given is of a store object, the custom objects map will be\n",
    "  read from the logged custom object map artifact of the model. **Notice**: The custom objects will be imported in the\n",
    "  order they came in this dictionary (or json). If a custom object is depended on another, make sure to\n",
    "  put it below the one it relies on.\n",
    "* `custom_objects_directory`: Path to the directory with all the python files required for the custom objects. Can be\n",
    "  passed as a zip file as well (will be extracted during the start of the run).\n",
    "\n",
    "> Notice: The parameters for additional arguments `model_kwargs`, `train_kwargs` and `apply_mlrun_kwargs` can be\n",
    "  also passed in the global `kwargs` with the matching prefixes: `\"MODEL_\"`, `\"TRAIN_\"`, `\"MLRUN_\"`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outputs\n",
    "\n",
    "* **Trained model** - The trained model will be logged as a `ModelArtifact` with all the following artifacts registered\n",
    "  to it.\n",
    "* **Test dataset** - The test set used to test the model post training will be logged as a `DatasetArtifact`.\n",
    "* **Plots** - Informative plots regarding the model like confusion matrix and features importance are drawn and logged\n",
    "  as `PlotArtifact`s.\n",
    "* **Results** - List of all the calculations of metrics tested on the testing set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example\n",
    "\n",
    "First, we will import the Auto Trainer from the Functions Marketplace using MLRun's `import_function` function:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mlrun\n",
    "\n",
    "auto_trainer = mlrun.import_function(\"hub://auto_trainer\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assuming we have a dataset (in the example below we provide a URL to a csv file), all that is needed to be done now is\n",
    "to run the Auto Trainer using the training handler passing our desired parameters:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_url = \"https://s3.wasabisys.com/iguazio/data/function-marketplace-data/xgb_trainer/classifier-data.csv\"\n",
    "\n",
    "training_run = auto_trainer.run(\n",
    "    handler=\"train\",\n",
    "    inputs={\"dataset\": dataset_url},\n",
    "    params={\n",
    "        # Model parameters:\n",
    "        \"model_class\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "        \"model_kwargs\": {\"max_depth\": 8},  # Could be also passed as \"MODEL_max_depth\": 8\n",
    "        # Dataset parameters:\n",
    "        \"train_test_split_size\": 0.3,\n",
    "        \"random_state\": 7,\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can review the function's outputs and view its artifacts:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_run.outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_run.artifact('confusion-matrix').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating\n",
    "\n",
    "The `\"evaluate\"` handler is used to test the model on a given testing set and log its results. This is a common phase in\n",
    "every model life cycle and should be done periodically on updated testing sets to know your model is still in business.\n",
    "The function is using SciKit-Learn's API for evaluation, meaning the function follows the structure bellow:\n",
    "\n",
    "1. **Get the data**: Get the testing dataset passed to a local path.\n",
    "2. **Get the model**: Get the model object out of the `ModelArtifact` URI.\n",
    "3. **Predict**: Call the model's `predict` (and `predict_proba` if needed) method to test it on the testing set.\n",
    "4. **Log**: Test the model on the testing set and log the results and artifacts.\n",
    "\n",
    "MLRun is orchestrating on all the steps above. The evaluation is done with our shortcut function `apply_mlrun` that\n",
    "enable the automatic logging and further features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameters\n",
    "\n",
    "* `context` - MLRun context.\n",
    "\n",
    "**Model Parameters**\n",
    "\n",
    "*Parameters to load a logged model.*\n",
    "\n",
    "* `model_path`: `str` - A `ModelArtifact` URI to load.\n",
    "\n",
    "**Data parameters**\n",
    "\n",
    "*Parameters to get a dataset and prepare it for training, splitting into training and testing if required.*\n",
    "\n",
    "* `dataset`: `Union[str, list, dict]` - The dataset to train the model on.\n",
    "  * Can be passed as part of `inputs` to be parsed as `mlrun.DataItem`, meaning it supports either a URI or a\n",
    "    FeatureVector.\n",
    "  * Can be passed as part of `params`, meaning it can be a `list` or a `dict`.\n",
    "* `drop_columns`: `Union[str, int, List[str], List[int]]` - columns to drop from the dataset. Can be passed as strings\n",
    "  representing the column names or integers representing the column numbers.\n",
    "* `label_columns`: `Union[str, int, List[str], List[int]]` - The target label(s) of the column(s) in the dataset. Can\n",
    "  be passed as strings representing the column names or integers representing the column numbers.\n",
    "\n",
    "**Predict parameters**\n",
    "\n",
    "*Parameters to pass to the `predict` method of the model object.*\n",
    "\n",
    "* `predict_kwargs`: `dict` - Additional parameters to pass onto the `predict` method.\n",
    "\n",
    "**Logging parameters**\n",
    "\n",
    "*Parameters to control the automatic logging feature of MLRun. You may adjust the logging outputs to your desire and if\n",
    "not passed, a default list of artifacts and metrics will be produced and calculated.*\n",
    "\n",
    "* `_artifacts`: `Dict[str, Union[list, dict]]` - Additional artifacts to produce post training. See the\n",
    "  `ArtifactsLibrary` of the desired framework to see the available list of artifacts.\n",
    "* `_metrics`: `Union[List[str], Dict[str, Union[list, dict]]]` - Additional metrics to calculate post training. See how\n",
    "  to pass metrics and custom metrics in the `MetricsLibrary` of the desired framework.\n",
    "* `apply_mlrun_kwargs`: `dict` - Framework specific `apply_mlrun` key word arguments. Refer to the framework of choice\n",
    "  to know more ([SciKit-Learn](), [XGBoost]() or [LightGBM]())\n",
    "\n",
    "**Custom objects parameters**\n",
    "\n",
    "*Parameters to include custom objects for the evaluation like custom metric code and artifact plans. Keep in mind that\n",
    "the custom objects used to train the model are not required for loading it, it will happen automatically.*\n",
    "\n",
    "* `custom_objects_map`: `Union[str, Dict[str, Union[str, List[str]]]]` - A map of all the custom objects required for\n",
    "  loading, training and testing the model. Can be passed as a dictionary or a json file path. Each key is a path to a\n",
    "  python file and its value is the custom object name to import from it. If multiple objects needed to be imported from\n",
    "  the same py file a list can be given. For example:\n",
    "  ```python\n",
    "  {\n",
    "      \"/.../custom_metric.py\": \"MyMetric\",\n",
    "      \"/.../custom_plans.py\": [\"plan1\", \"plan2\"]\n",
    "  }\n",
    "  ```\n",
    "  All the paths will be accessed from the given 'custom_objects_directory', meaning each py file will be read from\n",
    "  'custom_objects_directory/<MAP VALUE>'. If the model path given is of a store object, the custom objects map will be\n",
    "  read from the logged custom object map artifact of the model. **Notice**: The custom objects will be imported in the\n",
    "  order they came in this dictionary (or json). If a custom object is depended on another, make sure to\n",
    "  put it below the one it relies on.\n",
    "* `custom_objects_directory`: Path to the directory with all the python files required for the custom objects. Can be\n",
    "  passed as a zip file as well (will be extracted during the start of the run).\n",
    "\n",
    "> Notice: The parameters for additional arguments `predict_kwargs` and `apply_mlrun_kwargs` can be also passed in the\n",
    "global `kwargs` with the matching prefixes: `\"PREDICT_\"`, `\"MLRUN_\"`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outputs\n",
    "\n",
    "* **Evaluated model** - The evaluated model's `ModelArtifact`  is updated with all the following artifacts registered\n",
    "  to it.\n",
    "* **Test dataset** - The test set used to test the model post training will be logged as a `DatasetArtifact`.\n",
    "* **Plots** - Informative plots regarding the model like confusion matrix and features importance are drawn and logged\n",
    "  as `PlotArtifact`s.\n",
    "* **Results** - List of all the calculations of metrics tested on the testing set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example\n",
    "\n",
    "We will evaluate the model trained in the previous example using the `training_run` object. We will use the same\n",
    "function and for convenience, the same dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_run = auto_trainer.run(\n",
    "    handler=\"evaluate\",\n",
    "    inputs={\"dataset\": dataset_url},\n",
    "    params={\n",
    "        \"model\": training_run.outputs[\"model\"],  # Take the model from the previous training run.\n",
    "    },\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reviewing the evaluation outputs we can see the evaluation results and artifacts:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_run.outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting\n",
    "\n",
    "The `\"predict\"` handler is used to run a manual prediction using the model provided (can be sometimes referred to as\n",
    "\"batch_predict\"). Manually calling predict is usually used to test the model on specific samples or for manually\n",
    "serving the model, performing prediction when enough requests were collected. The function is simple and straight\n",
    "forward:\n",
    "\n",
    "1. **Get the model**: Get the model object out of the `ModelArtifact` URI.\n",
    "2. **Predict**: Call the model's `predict` (and `predict_proba` if needed) method and return its raw prediction as a\n",
    "  logged dataset.\n",
    "\n",
    "Getting the model is done with our shortcut function `apply_mlrun`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameters\n",
    "\n",
    "* `context` - MLRun context.\n",
    "\n",
    "**Model Parameters**\n",
    "\n",
    "*Parameters to load a logged model.*\n",
    "\n",
    "* `model_path`: `str` - A `ModelArtifact` URI to load.\n",
    "\n",
    "**Data parameters**\n",
    "\n",
    "*Parameters to get a dataset and prepare it for training, splitting into training and testing if required.*\n",
    "\n",
    "* `dataset`: `Union[str, list, dict]` - The dataset to train the model on.\n",
    "  * Can be passed as part of `inputs` to be parsed as `mlrun.DataItem`, meaning it supports either a URI or a\n",
    "    FeatureVector.\n",
    "  * Can be passed as part of `params`, meaning it can be a `list` or a `dict`.\n",
    "* `drop_columns`: `Union[str, int, List[str], List[int]]` - columns to drop from the dataset. Can be passed as strings\n",
    "  representing the column names or integers representing the column numbers.\n",
    "* `label_columns`: `Union[str, int, List[str], List[int]]` - The target label(s) to give the logged prediction. Can\n",
    "  be passed as strings representing the column names or integers representing the column numbers.\n",
    "\n",
    "**Predict parameters**\n",
    "\n",
    "*Parameters to pass to the `predict` method of the model object.*\n",
    "\n",
    "* `predict_kwargs`: `dict` - Additional parameters to pass onto the `predict` method.\n",
    "\n",
    "> Notice: The parameters for additional arguments `predict_kwargs` and `apply_mlrun_kwargs` can be also passed in the\n",
    "global `kwargs` with the matching prefixes: `\"PREDICT_\"`, `\"MLRUN_\"`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outputs\n",
    "\n",
    "The prediction the model yielded is logged as a `DatasetArtifact`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example\n",
    "\n",
    "We will run a prediction on a single sample using the model from the training run:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample = [-0.265115184, -1.932260063, 0.303991713, -1.863833476, -1.045634803]\n",
    "\n",
    "predicting_run = auto_trainer.run(\n",
    "    handler=\"predict\",\n",
    "    params={\n",
    "        \"dataset\": sample,  # Notice dataset is is `params` and not in `inputs` now as we pass a raw sample.\n",
    "        \"model\": training_run.outputs[\"model\"],  # Take the model from the previous training run.\n",
    "    },\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can get the prediction by:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicting_run.artifact('prediction').show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}