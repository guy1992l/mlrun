{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Serving\n",
    "\n",
    "We now wish to serve our model using **nuclio** in order to send an image of a digit we will write and classify it into its equivalnt numeric value. \n",
    "\n",
    "1. [Code Review](#section_1)\n",
    "2. [Serving Graph](#section_2)\n",
    "3. [Test](#section_3)\n",
    "4. [Deploy](#section_4)\n",
    "\n",
    "<img src=\"./mnist_serving_graph.png\" alt=\"MNIST serving graph\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=\"section_1\"></a>\n",
    "\n",
    "## 1. Code Review\n",
    "\n",
    "The serving code will have the following components as seen in the image above:\n",
    "\n",
    "1. Import NumPy and PIL to handle the images.\n",
    "2. Preprocess the inputs.\n",
    "3. Postprocess the model outputs.\n",
    "\n",
    "We will review each component briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Module Imports\n",
    "\n",
    "We will use PIL to grayscale and resize the input image and NumPy to hold the image as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Preprocess the Inputs\n",
    "\n",
    "Before inferring the images thorugh the model, each image must be in shape of 28x28x1. So, we will grayscale the image to have only 1 channel and resize it to 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(event: dict) -> Dict[str, List[np.ndarray]]:\n",
    "    # Read the image:\n",
    "    digit_image = Image.fromarray(np.array(event[\"inputs\"], dtype=np.uint8))\n",
    "    \n",
    "    # Reduce the channels from 4 (RGBA) to 1 (Grayscale):\n",
    "    digit_image = ImageOps.grayscale(digit_image)\n",
    "\n",
    "    # Resize the image:\n",
    "    digit_image = digit_image.resize((28, 28))\n",
    "\n",
    "    # Convert to numpy array:\n",
    "    digit_image = np.expand_dims(np.array(digit_image), 0).tolist()\n",
    "\n",
    "    # Pack and return:\n",
    "    return {\"inputs\": digit_image}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Postprocess the model Outputs\n",
    "\n",
    "Process the Softmax layer output of the model into a dictionary holding the digit prediction and confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(event: dict) -> Dict[str, Union[int, float]]:\n",
    "    # Read the prediction from the model:\n",
    "    prediction = np.squeeze(event[\"outputs\"])\n",
    "    \n",
    "    # Get the digit:\n",
    "    predicted_digit = prediction.argmax()\n",
    "    \n",
    "    # Get the confidence:\n",
    "    predicted_confidence = prediction[predicted_digit]\n",
    "    \n",
    "    # Parse and return:\n",
    "    return {\n",
    "        \"digit\": int(predicted_digit),\n",
    "        \"confidence\": float(predicted_confidence),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=\"section_2\"></a>\n",
    "\n",
    "## 2. Serving Graph\n",
    "\n",
    "We will build the serving graph using the serving code in this notebook. To do so, we first need a project to get the model artifact from and then create our serving function. \n",
    "\n",
    "In addition to the code in this notebook, the model itself will be handled by a model server. We will use the basic TensorFlow.Keras model server available in MLRun at `mlrun.frameworks.tf_keras.TFKerasModelServer`. \n",
    "\n",
    "> You can inherit it or create your own Model Server class `ModelServer`. To learn more check out the docs of [serving]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Get the Project\n",
    "\n",
    "We will use the `get_or_create_project` function to get our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-09-18 16:29:23,992 [info] loaded project mnist-classifier from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "# Set our project's name:\n",
    "project_name = \"mnist-classifier\"\n",
    "\n",
    "# Create the project:\n",
    "project = mlrun.get_or_create_project(name=project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Create a MLRun Function\n",
    "\n",
    "We will use the `code_to_function` function as seen before to convert the code in this notebook into a MLRun Function. This time we will set the function's kind as `\"serving\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.serving.ServingRuntime at 0x7f86d6c863d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the function parsing the notebook's code using 'code_to_function':\n",
    "serving_function = mlrun.code_to_function(\n",
    "    name=\"mnist-serving\",\n",
    "    kind=\"serving\",  # <- Serving function kind.\n",
    "    image=\"mlrun/ml-models\"\n",
    ")\n",
    "\n",
    "# Save the function in the project:\n",
    "project.set_function(serving_function)\n",
    "project.save()\n",
    "\n",
    "# Mount it:\n",
    "serving_function.apply(mlrun.platforms.auto_mount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Get the Model\n",
    "\n",
    "We will get our model using `get_artifact_uri`. Feel free to use different tags and models you trained yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model to load:\n",
    "model_name = \"mnist_model\"\n",
    "\n",
    "# Get the model artifact uri:\n",
    "model_path = project.get_artifact_uri(key=model_name, category=\"model\")\n",
    "\n",
    "# Choose the ModelServer according to the selected framework:\n",
    "model_server_class = \"mlrun.frameworks.tf_keras.TFKerasModelServer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Build the Serving Graph\n",
    "\n",
    "Our serving graph will have the following structure: Preprocess &rarr; Model Inference &rarr; Postprocess\n",
    "\n",
    "We will use the `set_topology` method to initialize and get the graph object. From there we will use the graph's `to` method to build its steps, sending the inputs to **preprocess**, then to the **Model Server** and finally to **postprocess** where we will call to `respond`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"614pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 614.26 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 610.2611,-40 610.2611,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"38.5476,-.0493 40.698,-.1479 42.8263,-.2953 44.9236,-.4913 46.9815,-.7353 48.9917,-1.0266 50.9463,-1.3645 52.8377,-1.7479 54.6587,-2.1759 56.4025,-2.6472 58.0628,-3.1606 59.634,-3.7147 61.1107,-4.308 62.4882,-4.9388 63.7625,-5.6054 64.9302,-6.3059 65.9882,-7.0385 66.9343,-7.8012 67.7669,-8.5918 68.4849,-9.4082 69.0878,-10.2481 69.5758,-11.1093 69.9496,-11.9894 70.2102,-12.886 70.3595,-13.7965 70.3997,-14.7186 70.3334,-15.6497 70.1636,-16.5873 69.8937,-17.5287 69.5276,-18.4713 69.0691,-19.4127 68.5225,-20.3503 67.8923,-21.2814 67.1831,-22.2035 66.3996,-23.114 65.5464,-24.0106 64.6285,-24.8907 63.6504,-25.7519 62.617,-26.5918 61.5329,-27.4082 60.4024,-28.1988 59.2299,-28.9615 58.0197,-29.6941 56.7755,-30.3946 55.5012,-31.0612 54.2002,-31.692 52.8757,-32.2853 51.5309,-32.8394 50.1684,-33.3528 48.7908,-33.8241 47.4003,-34.2521 45.9989,-34.6355 44.5886,-34.9734 43.1708,-35.2647 41.7472,-35.5087 40.3189,-35.7047 38.8872,-35.8521 37.4531,-35.9507 36.0175,-36 34.5815,-36 33.146,-35.9507 31.7119,-35.8521 30.2801,-35.7047 28.8519,-35.5087 27.4282,-35.2647 26.0105,-34.9734 24.6001,-34.6355 23.1988,-34.2521 21.8083,-33.8241 20.4306,-33.3528 19.0681,-32.8394 17.7233,-32.2853 16.3989,-31.692 15.0979,-31.0612 13.8236,-30.3946 12.5794,-29.6941 11.3691,-28.9615 10.1967,-28.1988 9.0662,-27.4082 7.982,-26.5918 6.9486,-25.7519 5.9706,-24.8907 5.0526,-24.0106 4.1995,-23.114 3.4159,-22.2035 2.7067,-21.2814 2.0765,-20.3503 1.53,-19.4127 1.0715,-18.4713 .7053,-17.5287 .4355,-16.5873 .2657,-15.6497 .1993,-14.7186 .2395,-13.7965 .3888,-12.886 .6495,-11.9894 1.0232,-11.1093 1.5112,-10.2481 2.1141,-9.4082 2.8321,-8.5918 3.6647,-7.8012 4.6109,-7.0385 5.6689,-6.3059 6.8365,-5.6054 8.1108,-4.9388 9.4884,-4.308 10.9651,-3.7147 12.5362,-3.1606 14.1966,-2.6472 15.9404,-2.1759 17.7614,-1.7479 19.6528,-1.3645 21.6074,-1.0266 23.6176,-.7353 25.6755,-.4913 27.7728,-.2953 29.901,-.1479 32.0515,-.0493 34.2154,0 36.3837,0 38.5476,-.0493\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.2995\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">start</text>\n",
       "</g>\n",
       "<!-- preprocess -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>preprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"168.9935\" cy=\"-18\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.9935\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocess</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;preprocess -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;preprocess</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M69.729,-18C77.9676,-18 87.0729,-18 96.3281,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.3959,-21.5001 106.3959,-18 96.3958,-14.5001 96.3959,-21.5001\"/>\n",
       "</g>\n",
       "<!-- mnist_classifier -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>mnist_classifier</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"351.8805\" cy=\"-18\" rx=\"84.485\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"351.8805\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mnist_classifier</text>\n",
       "</g>\n",
       "<!-- preprocess&#45;&gt;mnist_classifier -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>preprocess&#45;&gt;mnist_classifier</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.4213,-18C239.677,-18 248.2846,-18 256.9341,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.0885,-21.5001 267.0885,-18 257.0884,-14.5001 257.0885,-21.5001\"/>\n",
       "</g>\n",
       "<!-- postprocess -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>postprocess</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"539.317\" cy=\"-18\" rx=\"66.8882\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"539.317\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">postprocess</text>\n",
       "</g>\n",
       "<!-- mnist_classifier&#45;&gt;postprocess -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>mnist_classifier&#45;&gt;postprocess</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M436.5507,-18C445.0342,-18 453.6177,-18 462.0193,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"462.1585,-21.5001 472.1584,-18 462.1584,-14.5001 462.1585,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f86d6969290>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the topology and get the graph object:\n",
    "graph = serving_function.set_topology(\"flow\", engine=\"async\")\n",
    "\n",
    "# Build the serving graph:\n",
    "graph.to(handler=\"preprocess\", name=\"preprocess\")\\\n",
    "     .to(class_name=model_server_class, name=\"mnist_classifier\", model_path=model_path)\\\n",
    "     .to(handler=\"postprocess\", name=\"postprocess\").respond()\n",
    "\n",
    "# Plot to graph:\n",
    "graph.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=\"section_3\"></a>\n",
    "\n",
    "## 3. Test \n",
    "\n",
    "To test our serving function, we will create a mock server (simulator). Its like deploying the serving graph locally and this way we can debug more easily and quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Create a Mock Server\n",
    "\n",
    "We will create a mock server (simulator) using the function `to_mock_server()` and test the graph with the following image:\n",
    "\n",
    "![](./mnist_digit.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-09-18 16:29:48,616 [info] model mnist_classifier was loaded\n"
     ]
    }
   ],
   "source": [
    "# Create our server:\n",
    "server = serving_function.to_mock_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Run the Test\n",
    "\n",
    "In order to send the image to the mock server, we will use the `server.test` method. This method expects two main arguments:\n",
    "* `path` - Path to the method inside the `TFKerasModelServer`. We will be using the `predict` method.\n",
    "* `body` - A JSON serializable input to send to our serving pipeline.\n",
    "\n",
    "We will load our image and send it, expecting to get **5** with high confidence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'digit': 5, 'confidence': 0.9938642978668213}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load our test image:\n",
    "test_image = np.array(Image.open(\"./mnist_digit.png\")).tolist()\n",
    "\n",
    "# Infer thourgh the serving graph:\n",
    "server.test(path='/predict', body={\"inputs\": test_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=\"section_4\"></a>\n",
    "\n",
    "## 4. Deploy\n",
    "\n",
    "Now we will deploy a realtime serverless function. If you installed `ipycanvas` you can draw your own numbers and send them to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Deploy a Realtime Serverless Function\n",
    "\n",
    "Deploying is very easy, simply call the `deploy` method to deploy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-09-18 16:29:49,142 [info] Starting remote function deploy\n",
      "2022-09-18 16:29:49  (info) Deploying function\n",
      "2022-09-18 16:29:49  (info) Building\n",
      "2022-09-18 16:29:50  (info) Staging files and preparing base images\n",
      "2022-09-18 16:29:50  (info) Building processor image\n",
      "2022-09-18 16:32:15  (info) Build complete\n",
      "2022-09-18 16:32:35  (info) Function deploy complete\n",
      "> 2022-09-18 16:32:36,333 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-mnist-classifier-guyl-mnist-serving.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['mnist-classifier-guyl-mnist-serving-mnist-classifier-guyl.default-tenant.app.yh43.iguazio-cd1.com/']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://mnist-classifier-guyl-mnist-serving-mnist-classifier-guyl.default-tenant.app.yh43.iguazio-cd1.com/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy:\n",
    "serving_function.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Draw and Classify\n",
    "\n",
    "In order to test our realtime serving function, we can use the method `invoke` which takes the same two argumetns as `test` of the mock server.\n",
    "\n",
    "With `ipycanvas` we will create a canvas for drawing digits and send them to the model by running the code block after. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import HBox, Button\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "\n",
    "# Create the canvas:\n",
    "width = 200\n",
    "height = 200\n",
    "canvas = Canvas(width=width, height=height, sync_image_data=True)\n",
    "\n",
    "# Define the 'on_mouse' actions functions to draw on the canvas:\n",
    "is_drawing = False  # Whether to draw on the canvas.\n",
    "position = None  # type: Tuple[float, float]  # Last known position holder.\n",
    "\n",
    "def on_mouse_down(x, y):\n",
    "    global is_drawing\n",
    "    global position\n",
    "    \n",
    "    # Mark drawing should begin and store the first position:\n",
    "    is_drawing = True\n",
    "    position = (x, y)\n",
    "\n",
    "def on_mouse_move(x, y):\n",
    "    global is_drawing\n",
    "    global position\n",
    "    \n",
    "    # If mouse is not down while moving (not drawing) return:\n",
    "    if not is_drawing:\n",
    "        return\n",
    "    \n",
    "    # Draw while saving the last position:\n",
    "    with hold_canvas(canvas):\n",
    "        canvas.stroke_line(position[0], position[1], x, y)\n",
    "        position = (x, y)\n",
    "\n",
    "def on_mouse_up(x, y):\n",
    "    global is_drawing\n",
    "    global position\n",
    "\n",
    "    # Mark drawing has ended:\n",
    "    is_drawing = False\n",
    "    \n",
    "    # Draw the last dot:\n",
    "    canvas.stroke_line(position[0], position[1], x, y)\n",
    "\n",
    "# Set the 'on_mouse' actions:\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "\n",
    "# Configure the canvas style:\n",
    "canvas.fill_style = \"black\"  # MNIST are with black background.\n",
    "canvas.stroke_style = \"white\"  # MNIST digits are white.\n",
    "canvas.line_width = 15\n",
    "canvas.line_cap = 'round'\n",
    "canvas.fill_rect(0, 0, width, height)\n",
    "\n",
    "# Create the 'clear' button:\n",
    "clear_button = Button(\n",
    "    description='Clear',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Clear the canvas drawings',\n",
    "    icon='trash'\n",
    ")\n",
    "\n",
    "# Define the 'on_click' action function:\n",
    "def on_click(button):\n",
    "    canvas.fill_rect(0, 0, width, height)\n",
    "\n",
    "# Set the 'on_click' action function:\n",
    "clear_button.on_click(on_click)\n",
    "\n",
    "# Present the canvas and the button on a horizontal layout:\n",
    "HBox([canvas, clear_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Get the image drawn from the canvas:\n",
    "digit_image = canvas.get_image_data()\n",
    "\n",
    "# Infer thourgh the realtime serving graph:\n",
    "serving_function.invoke(path='/predict', body={\"inputs\": digit_image.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**We hope you had fun MLRunning!**\n",
    "\n",
    "If you have any comments, questions, suggestions, feel free to contact us at mlrun@iguazio.com!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
